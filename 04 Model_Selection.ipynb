{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>XGBoost</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#Catboost\" data-toc-modified-id=\"Catboost-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Catboost</a></span></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Combine-RF,-CB-and-GB\" data-toc-modified-id=\"Combine-RF,-CB-and-GB-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Combine RF, CB and GB</a></span></li><li><span><a href=\"#Plot-AUC-Curve\" data-toc-modified-id=\"Plot-AUC-Curve-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Plot AUC Curve</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#Cat-Boost\" data-toc-modified-id=\"Cat-Boost-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Cat Boost</a></span></li><li><span><a href=\"#Random-Forest,-Cat-Boost,-Gradient-Boost\" data-toc-modified-id=\"Random-Forest,-Cat-Boost,-Gradient-Boost-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Random Forest, Cat Boost, Gradient Boost</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bids_df_combined = pd.read_csv('combined2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_df: 2013 / 2013\n",
      "Length of test_df: 4700 / 4700\n"
     ]
    }
   ],
   "source": [
    "train_df = bids_df_combined.loc[bids_df_combined.outcome != 'Unknown']\n",
    "test_df = bids_df_combined.loc[bids_df_combined.outcome == 'Unknown']\n",
    "print(f'Length of train_df: {len(train_df)} / 2013')\n",
    "print(f'Length of test_df: {len(test_df)} / 4700')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bidder_id', 'payment_account', 'address', 'outcome',\n",
       "       'min_bids_per_auction', 'max_bids_per_auction', 'mean_bids_per_auction',\n",
       "       'median_bids_per_auction', 'total_bids', 'num_of_auctions',\n",
       "       'min_bids_per_url', 'max_bids_per_url', 'mean_bids_per_url',\n",
       "       'median_bids_per_url', 'num_of_url_used', 'min_bids_per_ip',\n",
       "       'max_bids_per_ip', 'mean_bids_per_ip', 'median_bids_per_ip',\n",
       "       'num_of_ip_used', 'bids_in_set1', 'bids_in_set2', 'bids_in_set3',\n",
       "       'bids_in_first3', 'bids_in_last3', 'mean_bid_per_auction_during_peak',\n",
       "       'mean_time_between_bids', 'median_time_between_bids', 'num_of_merch',\n",
       "       'unique_devices_used', 'unique_countries_used', 'ip_used_by_bot',\n",
       "       'fraction_of_ips_used_by_bot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bids_df_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the 5 bots with only one total_bid\n",
    "train_df = train_df.loc[(train_df.outcome!='1.0') | (train_df.total_bids!=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Model Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['min_bids_per_auction', 'max_bids_per_auction', 'mean_bids_per_auction',\n",
    "       'median_bids_per_auction', 'total_bids', 'num_of_auctions',\n",
    "       'min_bids_per_url', 'max_bids_per_url', 'mean_bids_per_url',\n",
    "       'median_bids_per_url', 'num_of_url_used', 'min_bids_per_ip',\n",
    "       'max_bids_per_ip', 'mean_bids_per_ip', 'median_bids_per_ip',\n",
    "       'num_of_ip_used', 'bids_in_set1', 'bids_in_set2', 'bids_in_set3','bids_in_first3','bids_in_last3',\n",
    "           'mean_bid_per_auction_during_peak','mean_time_between_bids','median_time_between_bids']\n",
    "X = train_df[features]\n",
    "y = train_df['outcome'].apply(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cherylperyl/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:09:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:09:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:09:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:09:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:10:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:10:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:10:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:10:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:10:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:10:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The Accuracy for each fold is: [1.0, 1.0, 1.0, 0.9523809523809523, 1.0, 1.0, 0.9523809523809523, 0.9523809523809523, 1.0, 1.0, 0.9, 1.0, 1.0, 0.95, 1.0, 0.95, 1.0, 0.95, 0.95, 1.0, 0.95, 0.9, 1.0, 1.0, 1.0, 1.0, 0.95, 0.85, 0.85, 0.95, 1.0, 0.95, 0.9, 0.95, 1.0, 0.95, 0.95, 1.0, 0.85, 0.95, 1.0, 0.95, 0.95, 0.95, 0.9, 1.0, 1.0, 0.95, 0.9, 0.95, 0.9, 0.9, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 0.85, 1.0, 1.0, 0.95, 0.95, 0.9, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 0.95, 1.0, 0.95, 0.95, 0.95, 0.95, 1.0, 0.95, 1.0, 0.85, 0.9, 0.95, 1.0, 1.0, 0.95, 0.8, 0.95, 0.85, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 0.95, 0.95, 0.95, 1.0, 0.9]\n",
      "The average accuracy is: 0.9590714285714286\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "kf = KFold(n_splits=100)\n",
    "\n",
    "model = xgb.XGBClassifier(random_state=5)\n",
    "\n",
    "k_fold_Accuracy = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    xgb_model = model.fit(X_train,y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    k_fold_Accuracy.append(accuracy)\n",
    "    \n",
    "print('The Accuracy for each fold is:', k_fold_Accuracy)\n",
    "print('The average accuracy is:', statistics.mean(k_fold_Accuracy)) \n",
    "# 0.9590714285714286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for each fold is: [1.0, 1.0, 1.0, 0.9523809523809523, 1.0, 1.0, 0.9523809523809523, 0.9523809523809523, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 0.95, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 0.95, 0.95, 0.95, 0.95, 0.9, 0.95, 0.95, 0.95, 0.95, 1.0, 0.9, 0.95, 1.0, 0.95, 0.95, 0.95, 0.9, 0.95, 0.95, 0.95, 0.9, 1.0, 0.9, 0.85, 1.0, 1.0, 1.0, 0.9, 0.95, 0.95, 0.85, 1.0, 0.95, 0.95, 0.95, 1.0, 1.0, 0.9, 1.0, 0.95, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 0.95, 0.9, 0.85, 0.9, 1.0, 1.0, 0.95, 0.8, 0.95, 0.9, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.95, 0.95, 1.0, 1.0, 0.9]\n",
      "The average accuracy is: 0.9605714285714285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "kf = KFold(n_splits=100)\n",
    "\n",
    "model = RandomForestClassifier(random_state=5, n_estimators=225)\n",
    "\n",
    "k_fold_Accuracy = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    rfc_model = model.fit(X_train,y_train)\n",
    "    y_pred = rfc_model.predict(X_test)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    k_fold_Accuracy.append(accuracy)\n",
    "\n",
    "print('The Accuracy for each fold is:', k_fold_Accuracy)\n",
    "print('The average accuracy is:', statistics.mean(k_fold_Accuracy)) \n",
    "\n",
    "# 0.9605714285714285"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for each fold is: [1.0, 1.0, 1.0, 0.9523809523809523, 1.0, 1.0, 0.9523809523809523, 0.9523809523809523, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.95, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.85, 0.9, 0.95, 1.0, 0.95, 0.9, 0.95, 0.95, 0.95, 0.95, 1.0, 0.9, 0.95, 1.0, 0.95, 0.95, 0.95, 0.9, 0.95, 1.0, 0.95, 0.9, 1.0, 0.9, 0.9, 1.0, 1.0, 1.0, 0.9, 0.95, 0.95, 0.85, 1.0, 0.95, 0.95, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 0.95, 0.85, 0.85, 1.0, 1.0, 1.0, 0.95, 0.85, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.95, 0.95, 1.0, 1.0, 0.9]\n",
      "The average accuracy is: 0.9635714285714285\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "kf = KFold(n_splits=100)\n",
    "\n",
    "model = CatBoostClassifier(random_seed=5)\n",
    "\n",
    "k_fold_Accuracy = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    cbc_model = model.fit(X_train,y_train,verbose=False)\n",
    "    y_pred = cbc_model.predict(X_test)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    k_fold_Accuracy.append(accuracy)\n",
    "    \n",
    "print('The Accuracy for each fold is:', k_fold_Accuracy)\n",
    "print('The average accuracy is:', statistics.mean(k_fold_Accuracy))\n",
    "# 0.9635714285714285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy is: 0.9557780404906162 0\n",
      "The average accuracy is: 0.9537929166050934 1\n",
      "The average accuracy is: 0.9532904783015616 2\n",
      "The average accuracy is: 0.952302842224521 3\n",
      "The average accuracy is: 0.9542879661100439 4\n",
      "The average accuracy is: 0.9532904783015614 5\n",
      "The average accuracy is: 0.9547854785478548 6\n",
      "The average accuracy is: 0.9547879414807152 7\n",
      "The average accuracy is: 0.9552780651199448 8\n",
      "The average accuracy is: 0.9542855031771834 9\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "depth=[i for i in range(10)] #3,7\n",
    "\n",
    "for d in depth:\n",
    "    model = CatBoostClassifier(random_seed=5, iterations=1000,depth=3,l2_leaf_reg=d)\n",
    "\n",
    "    k_fold_Accuracy = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        cbc_model = model.fit(X_train,y_train,verbose=False)\n",
    "        y_pred = cbc_model.predict(X_test)\n",
    "\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        k_fold_Accuracy.append(accuracy)\n",
    "\n",
    "    #print('The Accuracy for each fold is:', k_fold_Accuracy)\n",
    "    print('The average accuracy is:', statistics.mean(k_fold_Accuracy), d)\n",
    "# previous: 0.9577557755775578\n",
    "# latest:   0.9567632136347963\n",
    "# latest2:  0.9577607014432786\n",
    "# latest3:  0.9547780897492735"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=300)\n",
    "\n",
    "k_fold_accuracy = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    log_reg_model = log_reg.fit(X_train, y_train)\n",
    "    y_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    k_fold_accuracy.append(accuracy)\n",
    "    \n",
    "print('The accuracy for each fold is:', k_fold_accuracy)\n",
    "print('The average accuracy is:', statistics.mean(k_fold_accuracy))\n",
    "# previous: 0.9408625190877297\n",
    "# latest:   0.943342692478203\n",
    "# latest2:  0.9438377419831535"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine RF, CB and GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for each fold is: [1.0, 1.0, 1.0, 0.9523809523809523, 1.0, 1.0, 0.9523809523809523, 0.9523809523809523, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 0.95, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 0.9, 0.95, 0.95, 0.95, 0.9, 0.95, 0.95, 0.95, 0.95, 1.0, 0.9, 0.95, 1.0, 0.95, 0.95, 0.95, 0.9, 0.95, 0.95, 0.95, 0.9, 1.0, 0.9, 0.85, 1.0, 1.0, 1.0, 0.9, 0.95, 0.95, 0.85, 1.0, 0.95, 0.95, 0.95, 1.0, 1.0, 0.9, 1.0, 0.95, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 0.95, 0.9, 0.85, 0.9, 1.0, 1.0, 0.95, 0.8, 0.95, 0.9, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.95, 0.95, 1.0, 1.0, 0.9]\n",
      "The average accuracy is: 0.9600714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "\n",
    "kf = KFold(n_splits=100)\n",
    "model1 = RandomForestClassifier(random_state=5, n_estimators=225)\n",
    "model2 = GradientBoostingClassifier(learning_rate=0.01,random_state=5) \n",
    "model3 = CatBoostClassifier(random_seed=5)\n",
    "\n",
    "k_fold_accuracy = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model1.fit(X_train,y_train)\n",
    "    model2.fit(X_train,y_train)\n",
    "    model3.fit(X_train,y_train,verbose=False)\n",
    "    \n",
    "    pred1 = model1.predict(X_test)\n",
    "    pred2 = model2.predict(X_test)\n",
    "    pred3 = model3.predict(X_test)\n",
    "    \n",
    "    final_pred = []\n",
    "    for i in range(0,len(X_test)):\n",
    "        final_pred.append(statistics.mode([pred1[i],pred2[i],pred3[i]]))\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, final_pred)\n",
    "    k_fold_accuracy.append(accuracy)\n",
    "    \n",
    "print('The accuracy for each fold is:', k_fold_accuracy)\n",
    "print('The average accuracy is:', statistics.mean(k_fold_accuracy)) \n",
    "\n",
    "# Record latest results here\n",
    "# 0.9605714285714285 used mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [20, 4700]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-b3368b8a6232>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mfalse_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtest_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \"\"\"\n\u001b[0;32m--> 775\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    776\u001b[0m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    257\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20, 4700]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "n_estimators = [i for i in range(99, 401)]\n",
    "train_results = []\n",
    "test_results = []\n",
    "for estimator in n_estimators:\n",
    "    rf = RandomForestClassifier(n_estimators=estimator, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_pred = rf.predict(X_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "    \n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit features here\n",
    "features = ['min_bids_per_auction', 'max_bids_per_auction', 'mean_bids_per_auction',\n",
    "       'median_bids_per_auction', 'total_bids', 'num_of_auctions',\n",
    "       'min_bids_per_url', 'max_bids_per_url', 'mean_bids_per_url',\n",
    "       'median_bids_per_url', 'num_of_url_used', 'min_bids_per_ip',\n",
    "       'max_bids_per_ip', 'mean_bids_per_ip', 'median_bids_per_ip',\n",
    "       'num_of_ip_used', 'bids_in_set1', 'bids_in_set2', 'bids_in_set3','bids_in_first3','bids_in_last3',\n",
    "           'mean_bid_per_auction_during_peak','mean_time_between_bids','median_time_between_bids']\n",
    "\n",
    "# do not edit this part\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['outcome'].apply(float)\n",
    "X_test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement model below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trees used :  225\n",
      "- final_pred_proba ready for submission -\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "\n",
    "# implement model here\n",
    "model = RandomForestClassifier(random_state=5, n_estimators=225)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('Number of Trees used : ', model.n_estimators) # Find out number of trees used. 100 is a default\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "final_pred_proba = list(y_pred_proba[:, 1])\n",
    "print('- final_pred_proba ready for submission -')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- final_pred_proba ready for submission -\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(random_seed=5,iterations=1000,depth=7,l2_leaf_reg=0)\n",
    "\n",
    "model.fit(X_train, y_train, verbose=False)  # set verbose=False if you find the logs too long\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "final_pred_proba = list(y_pred_proba[:, 1])\n",
    "print('- final_pred_proba ready for submission -')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest, Cat Boost, Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "\n",
    "model1 = RandomForestClassifier(random_state=5, n_estimators=225)\n",
    "model2 = GradientBoostingClassifier(learning_rate=0.01,random_state=5) \n",
    "model3 = CatBoostClassifier(random_seed=5)\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train,verbose=False)\n",
    "    \n",
    "pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "pred_proba3 = list((model3.predict_proba(X_test))[:, 1])\n",
    "    \n",
    "final_pred_proba = []\n",
    "for i in range(len(X_test)):\n",
    "    final_pred_proba.append(np.mean([pred_proba1[i], pred_proba2[i], pred_proba3[i]]))\n",
    "\n",
    "print('- final_pred_proba ready for submission -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4700"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORMING THE CSV FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before forming the csv file, ensure that you `.predict_proba` on your model into a var named `y_pred_proba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run these lines first to form list of predicted probabilities\n",
    "# one_model\n",
    "y_pred_proba_formatted = list(y_pred_proba[:, 1])\n",
    "#print(y_pred_proba_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidder_id_list = list(test_df.bidder_id) #4.7 bidders\n",
    "predictions_list = final_pred_proba #predict proba list\n",
    "\n",
    "pred_list = [['Id','Predicted']]\n",
    "for i in range(len(predictions_list)):\n",
    "    pred_list.append([bidder_id_list[i],predictions_list[i]])\n",
    "df = pd.DataFrame(pred_list[1:], columns = pred_list[0])\n",
    "\n",
    "df.to_csv('RF_CB_GB_avg_emsemble2.csv', index=False) # change file name everytime you have a new set of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013f9b8d1f462df4462e1c1216e441ba6e18</td>\n",
       "      <td>0.007053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0014e3b911d1420e43ced1dc4fc18fde0fd0c</td>\n",
       "      <td>0.006954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002828f800c5132e297cfe3d44fbde9aeac51</td>\n",
       "      <td>0.006992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0040cea6b93afd86768c365d89513ffb7c0ba</td>\n",
       "      <td>0.007323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00512db4ae953baed983a4bcfa335e7412013</td>\n",
       "      <td>0.038122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>ffd49be672b1ba493b07dccf29311045c5392</td>\n",
       "      <td>0.056802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>ffdd8ed91a683b0f2a8237798ebe9214e3c43</td>\n",
       "      <td>0.007188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>ffde8717e9a547d536a4e9c3f44782829c021</td>\n",
       "      <td>0.007273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>ffe66dcb4b34bdbb5e17d7db7b1395e3fbbb7</td>\n",
       "      <td>0.013193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>ffef2a34068ab5328795bc9ed2da46aa29626</td>\n",
       "      <td>0.014686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4700 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Id  Predicted\n",
       "0     0013f9b8d1f462df4462e1c1216e441ba6e18   0.007053\n",
       "1     0014e3b911d1420e43ced1dc4fc18fde0fd0c   0.006954\n",
       "2     002828f800c5132e297cfe3d44fbde9aeac51   0.006992\n",
       "3     0040cea6b93afd86768c365d89513ffb7c0ba   0.007323\n",
       "4     00512db4ae953baed983a4bcfa335e7412013   0.038122\n",
       "...                                     ...        ...\n",
       "4695  ffd49be672b1ba493b07dccf29311045c5392   0.056802\n",
       "4696  ffdd8ed91a683b0f2a8237798ebe9214e3c43   0.007188\n",
       "4697  ffde8717e9a547d536a4e9c3f44782829c021   0.007273\n",
       "4698  ffe66dcb4b34bdbb5e17d7db7b1395e3fbbb7   0.013193\n",
       "4699  ffef2a34068ab5328795bc9ed2da46aa29626   0.014686\n",
       "\n",
       "[4700 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure there are 4,700 rows before submission\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
