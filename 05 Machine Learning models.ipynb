{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#The-different-Model-Tests-I-want-to-do:\" data-toc-modified-id=\"The-different-Model-Tests-I-want-to-do:-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>The different Model Tests I want to do:</a></span></li><li><span><a href=\"#Load-data-and-split-into-real-X_train,-X_test,-y_train\" data-toc-modified-id=\"Load-data-and-split-into-real-X_train,-X_test,-y_train-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load data and split into real X_train, X_test, y_train</a></span></li><li><span><a href=\"#Pruning-Tree\" data-toc-modified-id=\"Pruning-Tree-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Pruning Tree</a></span></li><li><span><a href=\"#Test-Model-1---RF,-CB,-GB---average\" data-toc-modified-id=\"Test-Model-1---RF,-CB,-GB---average-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Test Model 1 - RF, CB, GB - average</a></span></li><li><span><a href=\"#Test-Model-2---RF,-CB,-GB---weighted-average-XXXXX\" data-toc-modified-id=\"Test-Model-2---RF,-CB,-GB---weighted-average-XXXXX-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Test Model 2 - RF, CB, GB - weighted average XXXXX</a></span></li><li><span><a href=\"#Test-Model-3---RF,-CB---average\" data-toc-modified-id=\"Test-Model-3---RF,-CB---average-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Test Model 3 - RF, CB - average</a></span></li><li><span><a href=\"#Test-Model-4---RF,-CB---weighted-average-XXXXX\" data-toc-modified-id=\"Test-Model-4---RF,-CB---weighted-average-XXXXX-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Test Model 4 - RF, CB - weighted average XXXXX</a></span></li><li><span><a href=\"#Test-Model-5---RF,-GB---average\" data-toc-modified-id=\"Test-Model-5---RF,-GB---average-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Test Model 5 - RF, GB - average</a></span></li><li><span><a href=\"#Test-Model-6---RF,-GB---weighted-average\" data-toc-modified-id=\"Test-Model-6---RF,-GB---weighted-average-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Test Model 6 - RF, GB - weighted average</a></span></li><li><span><a href=\"#Test-Model-7---RF,-RF,-RF,-RF,-RF---average\" data-toc-modified-id=\"Test-Model-7---RF,-RF,-RF,-RF,-RF---average-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Test Model 7 - RF, RF, RF, RF, RF - average</a></span></li><li><span><a href=\"#Test-Model-8---RF,-RF,-RF,-RF,-RF---max-voting\" data-toc-modified-id=\"Test-Model-8---RF,-RF,-RF,-RF,-RF---max-voting-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Test Model 8 - RF, RF, RF, RF, RF - max voting</a></span></li><li><span><a href=\"#Test-Model-9---CB-+-GB---average\" data-toc-modified-id=\"Test-Model-9---CB-+-GB---average-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Test Model 9 - CB + GB - average</a></span></li><li><span><a href=\"#Test-Model-10---CB-+-GB---weighted-average\" data-toc-modified-id=\"Test-Model-10---CB-+-GB---weighted-average-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Test Model 10 - CB + GB - weighted average</a></span></li><li><span><a href=\"#Test-Model-11---RF+-CB-+-GB-+-XGB---average\" data-toc-modified-id=\"Test-Model-11---RF+-CB-+-GB-+-XGB---average-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Test Model 11 - RF+ CB + GB + XGB - average</a></span></li><li><span><a href=\"#Test-Model-12---RF+-CB-+-GB-+-XGB---weighted-average\" data-toc-modified-id=\"Test-Model-12---RF+-CB-+-GB-+-XGB---weighted-average-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Test Model 12 - RF+ CB + GB + XGB - weighted average</a></span></li><li><span><a href=\"#Test-Model-13---RF-+-XGB---average\" data-toc-modified-id=\"Test-Model-13---RF-+-XGB---average-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>Test Model 13 - RF + XGB - average</a></span></li><li><span><a href=\"#Test-Model-14---RF-+-XGB---weighted-average\" data-toc-modified-id=\"Test-Model-14---RF-+-XGB---weighted-average-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>Test Model 14 - RF + XGB - weighted average</a></span></li><li><span><a href=\"#Test-Model-15---RF*5-max-vote-+-GB---weighted-average\" data-toc-modified-id=\"Test-Model-15---RF*5-max-vote-+-GB---weighted-average-18\"><span class=\"toc-item-num\">18&nbsp;&nbsp;</span>Test Model 15 - RF*5 max vote + GB - weighted average</a></span></li><li><span><a href=\"#Final-Model-1:-RF+CB+GB-(avg)\" data-toc-modified-id=\"Final-Model-1:-RF+CB+GB-(avg)-19\"><span class=\"toc-item-num\">19&nbsp;&nbsp;</span>Final Model 1: RF+CB+GB (avg)</a></span></li><li><span><a href=\"#Final-Model-2:-RF+CB+GB-(weighted-avg)\" data-toc-modified-id=\"Final-Model-2:-RF+CB+GB-(weighted-avg)-20\"><span class=\"toc-item-num\">20&nbsp;&nbsp;</span>Final Model 2: RF+CB+GB (weighted avg)</a></span></li><li><span><a href=\"#Final-Model-3:-RF+CB+GB-(mode)\" data-toc-modified-id=\"Final-Model-3:-RF+CB+GB-(mode)-21\"><span class=\"toc-item-num\">21&nbsp;&nbsp;</span>Final Model 3: RF+CB+GB (mode)</a></span></li><li><span><a href=\"#Final-Model-4:-RF+CB+GB+AB-(mean)\" data-toc-modified-id=\"Final-Model-4:-RF+CB+GB+AB-(mean)-22\"><span class=\"toc-item-num\">22&nbsp;&nbsp;</span>Final Model 4: RF+CB+GB+AB (mean)</a></span></li><li><span><a href=\"#Final-Model-5:-RF+CB-(avg)\" data-toc-modified-id=\"Final-Model-5:-RF+CB-(avg)-23\"><span class=\"toc-item-num\">23&nbsp;&nbsp;</span>Final Model 5: RF+CB (avg)</a></span></li><li><span><a href=\"#Final-Model-6:-RF+CB-(weighted-avg)\" data-toc-modified-id=\"Final-Model-6:-RF+CB-(weighted-avg)-24\"><span class=\"toc-item-num\">24&nbsp;&nbsp;</span>Final Model 6: RF+CB (weighted avg)</a></span></li><li><span><a href=\"#Final-Model-7:-RF*5-(avg)\" data-toc-modified-id=\"Final-Model-7:-RF*5-(avg)-25\"><span class=\"toc-item-num\">25&nbsp;&nbsp;</span>Final Model 7: RF*5 (avg)</a></span></li><li><span><a href=\"#Final-Model-8:-RF-+-GB---weighted\" data-toc-modified-id=\"Final-Model-8:-RF-+-GB---weighted-26\"><span class=\"toc-item-num\">26&nbsp;&nbsp;</span>Final Model 8: RF + GB - weighted</a></span></li><li><span><a href=\"#Parameters-for-SKLearn-Random-Forest\" data-toc-modified-id=\"Parameters-for-SKLearn-Random-Forest-27\"><span class=\"toc-item-num\">27&nbsp;&nbsp;</span>Parameters for SKLearn Random Forest</a></span></li><li><span><a href=\"#K-Fold-Validation-using-train_df-and-calculating-AUC-score\" data-toc-modified-id=\"K-Fold-Validation-using-train_df-and-calculating-AUC-score-28\"><span class=\"toc-item-num\">28&nbsp;&nbsp;</span>K-Fold Validation using train_df and calculating AUC score</a></span></li><li><span><a href=\"#Testing-Random-Forest-Parameters:\" data-toc-modified-id=\"Testing-Random-Forest-Parameters:-29\"><span class=\"toc-item-num\">29&nbsp;&nbsp;</span>Testing Random Forest Parameters:</a></span></li><li><span><a href=\"#Testing-CatBoost-Parameters:\" data-toc-modified-id=\"Testing-CatBoost-Parameters:-30\"><span class=\"toc-item-num\">30&nbsp;&nbsp;</span>Testing CatBoost Parameters:</a></span></li><li><span><a href=\"#Testing-GradientBoost-Parameters:\" data-toc-modified-id=\"Testing-GradientBoost-Parameters:-31\"><span class=\"toc-item-num\">31&nbsp;&nbsp;</span>Testing GradientBoost Parameters:</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The different Model Tests I want to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest of random forests (maybe do 5)        #w and w/o 5 bots #\n",
    "# random forests + CatBoost + GradientBoost    #w and w/o 5 bots #DONE   \n",
    "# random forests + CatBoost                    #w and w/o 5 bots #DONE\n",
    "# random forests + GradientBoost               #w and w/o 5 bots #DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and split into real X_train, X_test, y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4700, 43)\n",
      "(2008, 43)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['bidder_id', 'payment_account', 'address', 'outcome',\n",
       "       'mean_reaction_time', 'median_reaction_time', 'var_reaction_time',\n",
       "       'mean_bids_per_auction', 'median_bids_per_auction', 'mean_bids_per_day',\n",
       "       'total_bids', 'bids_in_firstthirty', 'bids_in_secondthirty',\n",
       "       'bids_in_lastthirty', 'bids_in_secondlastthirty',\n",
       "       'mean_time_variance_per_day', 'avg_bids_in_20mins',\n",
       "       'mean_bidder_downtime', 'median_bidder_downtime', 'var_bidder_downtime',\n",
       "       'time_between_diff_ips', 'min_bids_per_url', 'max_bids_per_url',\n",
       "       'mean_bids_per_url', 'median_bids_per_url', 'num_of_url_used',\n",
       "       'min_bids_per_ip', 'max_bids_per_ip', 'mean_bids_per_ip',\n",
       "       'median_bids_per_ip', 'num_of_ip_used', 'bids_in_set1', 'bids_in_set2',\n",
       "       'bids_in_set3', 'mean_bid_per_country', 'unique_devices_used',\n",
       "       'unique_countries_used', 'num_of_unique_auctions',\n",
       "       'mean_auction_bid_count_per_bidder', 'firstthirty_fraction',\n",
       "       'secondthirty_fraction', 'lastthirty_fraction',\n",
       "       'secondlastthirty_fraction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidder_df = pd.read_csv('combined10.csv')\n",
    "\n",
    "train_df = bidder_df.loc[bidder_df.outcome != 'Unknown']\n",
    "train_df = train_df.loc[(train_df.outcome!='1.0') | (train_df.total_bids!=1)] #remove if you wanna add the 5 bots w 1 bid\n",
    "\n",
    "test_df = bidder_df.loc[bidder_df.outcome =='Unknown']\n",
    "\n",
    "print(test_df.shape)\n",
    "print(train_df.shape)\n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2008, 39)\n",
      "(2008,)\n",
      "(4700, 39)\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "       'mean_reaction_time', 'median_reaction_time', 'var_reaction_time',\n",
    "       'mean_bids_per_auction', 'median_bids_per_auction', 'mean_bids_per_day',\n",
    "       'total_bids', 'bids_in_firstthirty', 'bids_in_secondthirty',\n",
    "       'bids_in_lastthirty', 'bids_in_secondlastthirty',\n",
    "       'mean_time_variance_per_day', 'avg_bids_in_20mins',\n",
    "       'mean_bidder_downtime', 'median_bidder_downtime', 'var_bidder_downtime',\n",
    "       'time_between_diff_ips', 'min_bids_per_url', 'max_bids_per_url',\n",
    "       'mean_bids_per_url', 'median_bids_per_url', 'num_of_url_used',\n",
    "       'min_bids_per_ip', 'max_bids_per_ip', 'mean_bids_per_ip',\n",
    "       'median_bids_per_ip', 'num_of_ip_used', 'bids_in_set1', 'bids_in_set2',\n",
    "       'bids_in_set3', 'mean_bid_per_country', 'unique_devices_used',\n",
    "       'unique_countries_used', 'num_of_unique_auctions',\n",
    "       'mean_auction_bid_count_per_bidder', 'firstthirty_fraction',\n",
    "       'secondthirty_fraction', 'lastthirty_fraction',\n",
    "       'secondlastthirty_fraction']\n",
    "\n",
    "X_train_real = train_df[features]\n",
    "y_train_real = train_df['outcome'].apply(float)\n",
    "X_test_real = test_df[features]\n",
    "\n",
    "\n",
    "print(X_train_real.shape)\n",
    "print(y_train_real.shape)\n",
    "print(X_test_real.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def k_fold_validation(model, X, y):\n",
    "#     y = train_df.outcome.apply(float)\n",
    "#     X = train_df[features]\n",
    "\n",
    "#     total_AUC = []\n",
    "\n",
    "#     random.seed(30)\n",
    "\n",
    "#     for i in range (1, 31):\n",
    "#         rand_state = random.randint(1, 30)\n",
    "#         y = train_df.outcome\n",
    "#         X = train_df[features]\n",
    "\n",
    "\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                             shuffle = True)\n",
    "\n",
    "    \n",
    "#         # Fit model\n",
    "#         decision_tree_model = model.fit(X_train, y_train)\n",
    "#         y_pred_proba = decision_tree_model.predict(X_test)\n",
    "        \n",
    "#         # Get the number of leaves in the model\n",
    "#         num_of_leaves = decision_tree_model.get_n_leaves()\n",
    "        \n",
    "#         # Get the depth of the tree\n",
    "#         depth_of_tree = decision_tree_model.get_depth()\n",
    "\n",
    "#         local_AUC_score = roc_auc_score(y_test, y_pred_proba)\n",
    "#         total_AUC.append(local_AUC_score)\n",
    "    \n",
    "#     return depth_of_tree, num_of_leaves, statistics.mean(total_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "# import pandas as pd\n",
    "\n",
    "# values = []\n",
    "# # Iteratively increase the number of samples required for each split (which limits the size of the tree)\n",
    "# for count in range(2, 200):\n",
    "\n",
    "#     # Create decision tree object\n",
    "#     model = DecisionTreeClassifier(random_state=1234, max_depth=8, min_samples_split=count)\n",
    "    \n",
    "#     # Calculate the kfold validation for the specific decision tree object\n",
    "#     depth_of_tree, num_of_leaves, local_auc = k_fold_validation(model, X, y)\n",
    "    \n",
    "#     # Formatting a print label\n",
    "#     label = 'Min Sample Split of ' + str(count) + ':'\n",
    "    \n",
    "#     # Printing the output\n",
    "#     print(label, depth_of_tree, num_of_leaves, local_auc)\n",
    "    \n",
    "#     values.append(local_auc)\n",
    "\n",
    "\n",
    "# model1 = RandomForestClassifier(random_state=5, n_estimators=1100, min_samples_split =  3,\n",
    "#                                     min_samples_leaf = 1, max_features = 35, max_depth = 130, bootstrap = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 1 - RF, CB, GB - average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "import random\n",
    "\n",
    "y = train_df.outcome.apply(float)\n",
    "X = train_df[features]\n",
    "\n",
    "total_AUC = []\n",
    "\n",
    "random.seed(13)\n",
    "\n",
    "for i in range (1, 101):\n",
    "    rand_state = random.randint(1, 30)\n",
    "    y = train_df.outcome\n",
    "    X = train_df[features]\n",
    "    print('Random_state number', str(i) + ':', rand_state)\n",
    "    print('-'*40)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "                                                        shuffle = True)\n",
    "\n",
    "\n",
    "    model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "                                    min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True, \n",
    "                                    criterion = 'entropy')\n",
    "    model2 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    "    model3 = GradientBoostingClassifier(learning_rate=0.01,random_state=5)\n",
    " \n",
    "    model1 = model1.fit(X_train,y_train)\n",
    "    model2 = model2.fit(X_train,y_train,verbose=False)\n",
    "    model3 = model3.fit(X_train, y_train)\n",
    "\n",
    "    pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "    pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "    pred_proba3 = list((model3.predict_proba(X_test))[:, 1])\n",
    "\n",
    "    test_pred_proba = []\n",
    "    for i in range(len(X_test)):\n",
    "        test_pred_proba.append(np.mean([pred_proba1[i], pred_proba2[i], pred_proba3[i]]))\n",
    "    \n",
    "    local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "    print('Local AUC score:', local_AUC_score)\n",
    "    total_AUC.append(local_AUC_score)\n",
    "    print('-'*40)\n",
    "\n",
    "avg_local_AUC_score = statistics.mean(total_AUC)\n",
    "sd = statistics.stdev(total_AUC)\n",
    "\n",
    "print('Avg local AUC score is:', avg_local_AUC_score)\n",
    "print('s.d =', sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 2 - RF, CB, GB - weighted average XXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "import random\n",
    "\n",
    "y = train_df.outcome.apply(float)\n",
    "X = train_df[features]\n",
    "\n",
    "total_AUC = []\n",
    "\n",
    "random.seed(13)\n",
    "\n",
    "for i in range (1, 101):\n",
    "    rand_state = random.randint(1, 30)\n",
    "    y = train_df.outcome\n",
    "    X = train_df[features]\n",
    "    print('Random_state number', str(i) + ':', rand_state)\n",
    "    print('-'*40)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "                                                        shuffle = True)\n",
    "\n",
    "\n",
    "    model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "                                    min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True, \n",
    "                                    criterion = 'entropy')\n",
    "    model2 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    "    model3 = GradientBoostingClassifier(learning_rate=0.01,random_state=5)\n",
    "\n",
    "    model1 = model1.fit(X_train,y_train)\n",
    "    model2 = model2.fit(X_train,y_train,verbose=False)\n",
    "    model3 = model3.fit(X_train, y_train)\n",
    "\n",
    "    pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "    pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "    pred_proba3 = list((model3.predict_proba(X_test))[:, 1])\n",
    "\n",
    "    test_pred_proba = []\n",
    "    for i in range(len(X_test)):\n",
    "        test_pred_proba.append((pred_proba1[i] * 0.6) + (pred_proba2[i] * 0.2) + (pred_proba3[i] * 0.2))\n",
    "    \n",
    "    local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "    print('Local AUC score:', local_AUC_score)\n",
    "    total_AUC.append(local_AUC_score)\n",
    "    print('-'*40)\n",
    "\n",
    "avg_local_AUC_score = statistics.mean(total_AUC)\n",
    "sd = statistics.stdev(total_AUC)\n",
    "\n",
    "print('Avg local AUC score is:', avg_local_AUC_score)\n",
    "print('s.d =', sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 3 - RF, CB - average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "\n",
    "# y = train_df.outcome.apply(float)\n",
    "# X = train_df[features]\n",
    "\n",
    "# total_AUC = 0\n",
    "\n",
    "# random.seed(13)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "#     rand_state = random.randint(1, 30)\n",
    "#     y = train_df.outcome\n",
    "#     X = train_df[features]\n",
    "#     print('Random_state number', str(i) + ':', rand_state)\n",
    "#     print('-'*40)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "\n",
    "#     model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "#                                     min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True, \n",
    "#                                     criterion = 'entropy')\n",
    "#     model2 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    "\n",
    "#     model1 = model1.fit(X_train,y_train)\n",
    "#     model2 = model2.fit(X_train,y_train,verbose=False)\n",
    "\n",
    "#     pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "\n",
    "#     test_pred_proba = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         test_pred_proba.append(np.mean([pred_proba1[i], pred_proba2[i]]))\n",
    "    \n",
    "#     local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "#     print('Local AUC score:', local_AUC_score)\n",
    "#     total_AUC += local_AUC_score\n",
    "#     print('-'*40)\n",
    "\n",
    "# avg_local_AUC_score = total_AUC/30\n",
    "\n",
    "# print('Avg local AUC score is:', avg_local_AUC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 4 - RF, CB - weighted average XXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "\n",
    "# y = train_df.outcome.apply(float)\n",
    "# X = train_df[features]\n",
    "\n",
    "# total_AUC = 0\n",
    "\n",
    "# random.seed(13)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "#     rand_state = random.randint(1, 30)\n",
    "#     y = train_df.outcome\n",
    "#     X = train_df[features]\n",
    "#     print('Random_state number', str(i) + ':', rand_state)\n",
    "#     print('-'*40)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "\n",
    "#     model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "#                                     min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True, \n",
    "#                                     criterion = 'entropy')\n",
    "#     model2 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    "\n",
    "#     model1 = model1.fit(X_train,y_train)\n",
    "#     model2 = model2.fit(X_train,y_train,verbose=False)\n",
    "\n",
    "#     pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "\n",
    "#     test_pred_proba = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         test_pred_proba.append((pred_proba1[i] * 0.7) + (pred_proba2[i] * 0.3))\n",
    "    \n",
    "#     local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "#     print('Local AUC score:', local_AUC_score)\n",
    "#     total_AUC += local_AUC_score\n",
    "#     print('-'*40)\n",
    "\n",
    "# avg_local_AUC_score = total_AUC/30\n",
    "\n",
    "# print('Avg local AUC score is:', avg_local_AUC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 5 - RF, GB - average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "\n",
    "# y = train_df.outcome.apply(float)\n",
    "# X = train_df[features]\n",
    "\n",
    "# total_AUC = 0\n",
    "\n",
    "# random.seed(30)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "#     rand_state = random.randint(1, 30)\n",
    "#     y = train_df.outcome\n",
    "#     X = train_df[features]\n",
    "#     print('Random_state number', str(i) + ':', rand_state)\n",
    "#     print('-'*40)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "\n",
    "#     model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "#                                     min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True)\n",
    "#     model2 = GradientBoostingClassifier(learning_rate=0.01,random_state=5)\n",
    "\n",
    "#     model1 = model1.fit(X_train,y_train)\n",
    "#     model2 = model2.fit(X_train, y_train)\n",
    "\n",
    "#     pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "\n",
    "#     test_pred_proba = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         test_pred_proba.append(np.mean([pred_proba1[i], pred_proba2[i]]))\n",
    "    \n",
    "#     local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "#     print('Local AUC score:', local_AUC_score)\n",
    "#     total_AUC += local_AUC_score\n",
    "#     print('-'*40)\n",
    "\n",
    "# avg_local_AUC_score = total_AUC/30\n",
    "\n",
    "# print('Avg local AUC score is:', avg_local_AUC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 6 - RF, GB - weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "import random\n",
    "\n",
    "y = train_df.outcome.apply(float)\n",
    "X = train_df[features]\n",
    "\n",
    "total_AUC = []\n",
    "\n",
    "random.seed(13)\n",
    "\n",
    "for i in range (1, 101):\n",
    "    rand_state = random.randint(1, 30)\n",
    "    y = train_df.outcome\n",
    "    X = train_df[features]\n",
    "    print('Random_state number', str(i) + ':', rand_state)\n",
    "    print('-'*40)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "                                                        shuffle = True)\n",
    "\n",
    "\n",
    "    model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "                                    min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True, \n",
    "                                    criterion = 'entropy')\n",
    "    model2 = GradientBoostingClassifier(learning_rate=0.01,random_state=5)\n",
    "\n",
    "    model1 = model1.fit(X_train,y_train)\n",
    "    model2 = model2.fit(X_train, y_train)\n",
    "\n",
    "    pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "    pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "\n",
    "    test_pred_proba = []\n",
    "    for i in range(len(X_test)):\n",
    "        test_pred_proba.append((pred_proba1[i] * 0.7) + (pred_proba2[i] * 0.3))\n",
    "    \n",
    "    local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "    print('Local AUC score:', local_AUC_score)\n",
    "    total_AUC.append(local_AUC_score)\n",
    "    print('-'*40)\n",
    "\n",
    "avg_local_AUC_score = statistics.mean(total_AUC)\n",
    "sd = statistics.stdev(total_AUC)\n",
    "\n",
    "print('Avg local AUC score is:', avg_local_AUC_score)\n",
    "print('s.d =', sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 7 - RF, RF, RF, RF, RF - average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "\n",
    "# y = train_df.outcome.apply(float)\n",
    "# X = train_df[features]\n",
    "\n",
    "# total_AUC = 0\n",
    "\n",
    "# random.seed(30)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "#     rand_state = random.randint(1, 30)\n",
    "#     y = train_df.outcome\n",
    "#     X = train_df[features]\n",
    "#     print('Random_state number', str(i) + ':', rand_state)\n",
    "#     print('-'*40)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "\n",
    "#     model1 = RandomForestClassifier(random_state=5, n_estimators=1000)\n",
    "#     model2 = RandomForestClassifier(random_state=5, n_estimators=1100)\n",
    "#     model3 = RandomForestClassifier(random_state=5, n_estimators=1200)\n",
    "#     model4 = RandomForestClassifier(random_state=5, n_estimators=1300)\n",
    "#     model5 = RandomForestClassifier(random_state=5, n_estimators=1400)\n",
    "\n",
    "#     model1 = model1.fit(X_train,y_train)\n",
    "#     model2 = model2.fit(X_train,y_train)\n",
    "#     model3 = model3.fit(X_train,y_train)\n",
    "#     model4 = model4.fit(X_train,y_train)\n",
    "#     model5 = model5.fit(X_train,y_train)\n",
    "\n",
    "#     pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba3 = list((model3.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba4 = list((model4.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba5 = list((model5.predict_proba(X_test))[:, 1])\n",
    "\n",
    "#     test_pred_proba = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         test_pred_proba.append(np.mean([pred_proba1[i], pred_proba2[i], pred_proba3[i], pred_proba4[i], pred_proba5[i]]))\n",
    "    \n",
    "#     local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "#     print('Local AUC score:', local_AUC_score)\n",
    "#     total_AUC += local_AUC_score\n",
    "#     print('-'*40)\n",
    "\n",
    "# avg_local_AUC_score = total_AUC/30\n",
    "\n",
    "# print('Avg local AUC score is:', avg_local_AUC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 8 - RF, RF, RF, RF, RF - max voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "\n",
    "# y = train_df.outcome.apply(float)\n",
    "# X = train_df[features]\n",
    "\n",
    "# total_AUC = 0\n",
    "\n",
    "# random.seed(30)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "#     rand_state = random.randint(1, 30)\n",
    "#     y = train_df.outcome\n",
    "#     X = train_df[features]\n",
    "#     print('Random_state number', str(i) + ':', rand_state)\n",
    "#     print('-'*40)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "\n",
    "#     model1 = RandomForestClassifier(random_state=5, n_estimators=1400)\n",
    "#     model2 = RandomForestClassifier(random_state=5, n_estimators=1500)\n",
    "#     model3 = RandomForestClassifier(random_state=5, n_estimators=1600)\n",
    "#     model4 = RandomForestClassifier(random_state=5, n_estimators=1700)\n",
    "#     model5 = RandomForestClassifier(random_state=5, n_estimators=1800)\n",
    "\n",
    "#     model1 = model1.fit(X_train,y_train)\n",
    "#     model2 = model2.fit(X_train,y_train)\n",
    "#     model3 = model3.fit(X_train,y_train)\n",
    "#     model4 = model4.fit(X_train,y_train)\n",
    "#     model5 = model5.fit(X_train,y_train)\n",
    "\n",
    "#     pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba3 = list((model3.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba4 = list((model4.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba5 = list((model5.predict_proba(X_test))[:, 1])\n",
    "\n",
    "#     test_pred_proba = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         test_pred_proba.append(statistics.mode([pred_proba1[i], pred_proba2[i], pred_proba3[i], \n",
    "#                                                 pred_proba4[i], pred_proba5[i]]))\n",
    "    \n",
    "#     local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "#     print('Local AUC score:', local_AUC_score)\n",
    "#     total_AUC += local_AUC_score\n",
    "#     print('-'*40)\n",
    "\n",
    "# avg_local_AUC_score = total_AUC/30\n",
    "\n",
    "# print('Avg local AUC score is:', avg_local_AUC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 9 - CB + GB - average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "\n",
    "# y = train_df.outcome.apply(float)\n",
    "# X = train_df[features]\n",
    "\n",
    "# total_AUC = 0\n",
    "\n",
    "# random.seed(30)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "#     rand_state = random.randint(1, 30)\n",
    "#     y = train_df.outcome\n",
    "#     X = train_df[features]\n",
    "#     print('Random_state number', str(i) + ':', rand_state)\n",
    "#     print('-'*40)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "\n",
    "#     model1 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    "#     model2 = GradientBoostingClassifier(learning_rate=0.01,random_state=5)\n",
    " \n",
    "#     model1 = model1.fit(X_train,y_train,verbose=False)\n",
    "#     model2 = model2.fit(X_train, y_train)\n",
    "\n",
    "#     pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "\n",
    "#     test_pred_proba = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         test_pred_proba.append(np.mean([pred_proba1[i], pred_proba2[i]]))\n",
    "    \n",
    "#     local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "#     print('Local AUC score:', local_AUC_score)\n",
    "#     total_AUC += local_AUC_score\n",
    "#     print('-'*40)\n",
    "\n",
    "# avg_local_AUC_score = total_AUC/30\n",
    "\n",
    "# print('Avg local AUC score is:', avg_local_AUC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 10 - CB + GB - weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "\n",
    "# y = train_df.outcome.apply(float)\n",
    "# X = train_df[features]\n",
    "\n",
    "# total_AUC = 0\n",
    "\n",
    "# random.seed(30)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "#     rand_state = random.randint(1, 30)\n",
    "#     y = train_df.outcome\n",
    "#     X = train_df[features]\n",
    "#     print('Random_state number', str(i) + ':', rand_state)\n",
    "#     print('-'*40)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "\n",
    "#     model1 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    "#     model2 = GradientBoostingClassifier(learning_rate=0.01,random_state=5)\n",
    " \n",
    "#     model1 = model1.fit(X_train,y_train,verbose=False)\n",
    "#     model2 = model2.fit(X_train, y_train)\n",
    "\n",
    "#     pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "\n",
    "#     test_pred_proba = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         test_pred_proba.append((pred_proba1[i] * 0.7) + (pred_proba2[i] * 0.3))\n",
    "    \n",
    "#     local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "#     print('Local AUC score:', local_AUC_score)\n",
    "#     total_AUC += local_AUC_score\n",
    "#     print('-'*40)\n",
    "\n",
    "# avg_local_AUC_score = total_AUC/30\n",
    "\n",
    "# print('Avg local AUC score is:', avg_local_AUC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 11 - RF+ CB + GB + XGB - average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "\n",
    "# y = train_df.outcome.apply(float)\n",
    "# X = train_df[features]\n",
    "\n",
    "# total_AUC = 0\n",
    "\n",
    "# random.seed(30)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "#     rand_state = random.randint(1, 30)\n",
    "#     y = train_df.outcome\n",
    "#     X = train_df[features]\n",
    "#     print('Random_state number', str(i) + ':', rand_state)\n",
    "#     print('-'*40)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "\n",
    "#     model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "#                                     min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True)\n",
    "#     model2 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    "#     model3 = GradientBoostingClassifier(learning_rate=0.01,random_state=5)\n",
    "#     model4 = xgb.XGBClassifier(random_state=5)\n",
    " \n",
    "#     model1 = model1.fit(X_train,y_train)\n",
    "#     model2 = model2.fit(X_train,y_train,verbose=False)\n",
    "#     model3 = model3.fit(X_train, y_train)\n",
    "#     model4 = model4.fit(X_train, y_train)\n",
    "\n",
    "#     pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba3 = list((model3.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba4 = list((model4.predict_proba(X_test))[:, 1])\n",
    "\n",
    "#     test_pred_proba = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         test_pred_proba.append(np.mean([pred_proba1[i], pred_proba2[i], pred_proba3[i], pred_proba4[i]]))\n",
    "    \n",
    "#     local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "#     print('Local AUC score:', local_AUC_score)\n",
    "#     total_AUC += local_AUC_score\n",
    "#     print('-'*40)\n",
    "\n",
    "# avg_local_AUC_score = total_AUC/30\n",
    "\n",
    "# print('Avg local AUC score is:', avg_local_AUC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 12 - RF+ CB + GB + XGB - weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "\n",
    "# y = train_df.outcome.apply(float)\n",
    "# X = train_df[features]\n",
    "\n",
    "# total_AUC = 0\n",
    "\n",
    "# random.seed(30)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "#     rand_state = random.randint(1, 30)\n",
    "#     y = train_df.outcome\n",
    "#     X = train_df[features]\n",
    "#     print('Random_state number', str(i) + ':', rand_state)\n",
    "#     print('-'*40)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "\n",
    "#     model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "#                                     min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True)\n",
    "#     model2 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    "#     model3 = GradientBoostingClassifier(learning_rate=0.01,random_state=5)\n",
    "#     model4 = xgb.XGBClassifier(random_state=5)\n",
    " \n",
    "#     model1 = model1.fit(X_train,y_train)\n",
    "#     model2 = model2.fit(X_train,y_train,verbose=False)\n",
    "#     model3 = model3.fit(X_train, y_train)\n",
    "#     model4 = model4.fit(X_train, y_train)\n",
    "\n",
    "#     pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba3 = list((model3.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba4 = list((model4.predict_proba(X_test))[:, 1])\n",
    "\n",
    "#     test_pred_proba = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         test_pred_proba.append((pred_proba1[i] * 0.5) + (pred_proba2[i] * 0.1) + (pred_proba3[i] * 0.2) + (pred_proba4[i] + 0.2))\n",
    "    \n",
    "#     local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "#     print('Local AUC score:', local_AUC_score)\n",
    "#     total_AUC += local_AUC_score\n",
    "#     print('-'*40)\n",
    "\n",
    "# avg_local_AUC_score = total_AUC/30\n",
    "\n",
    "# print('Avg local AUC score is:', avg_local_AUC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 13 - RF + XGB - average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "\n",
    "# y = train_df.outcome.apply(float)\n",
    "# X = train_df[features]\n",
    "\n",
    "# total_AUC = 0\n",
    "\n",
    "# random.seed(30)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "#     rand_state = random.randint(1, 30)\n",
    "#     y = train_df.outcome\n",
    "#     X = train_df[features]\n",
    "#     print('Random_state number', str(i) + ':', rand_state)\n",
    "#     print('-'*40)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "\n",
    "#     model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "#                                     min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True)\n",
    "#     model2 = xgb.XGBClassifier(random_state=5)\n",
    " \n",
    "#     model1 = model1.fit(X_train,y_train)\n",
    "#     model2 = model2.fit(X_train, y_train)\n",
    "\n",
    "#     pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "\n",
    "#     test_pred_proba = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         test_pred_proba.append(np.mean([pred_proba1[i], pred_proba2[i]]))\n",
    "    \n",
    "#     local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "#     print('Local AUC score:', local_AUC_score)\n",
    "#     total_AUC += local_AUC_score\n",
    "#     print('-'*40)\n",
    "\n",
    "# avg_local_AUC_score = total_AUC/30\n",
    "\n",
    "# print('Avg local AUC score is:', avg_local_AUC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 14 - RF + XGB - weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "\n",
    "# y = train_df.outcome.apply(float)\n",
    "# X = train_df[features]\n",
    "\n",
    "# total_AUC = 0\n",
    "\n",
    "# random.seed(30)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "#     rand_state = random.randint(1, 30)\n",
    "#     y = train_df.outcome\n",
    "#     X = train_df[features]\n",
    "#     print('Random_state number', str(i) + ':', rand_state)\n",
    "#     print('-'*40)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "\n",
    "#     model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "#                                     min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True)\n",
    "#     model2 = xgb.XGBClassifier(random_state=5)\n",
    " \n",
    "#     model1 = model1.fit(X_train,y_train)\n",
    "#     model2 = model2.fit(X_train, y_train)\n",
    "\n",
    "#     pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "\n",
    "#     test_pred_proba = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         test_pred_proba.append((pred_proba1[i] * 0.7) + (pred_proba2[i] * 0.3))\n",
    "    \n",
    "#     local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "#     print('Local AUC score:', local_AUC_score)\n",
    "#     total_AUC += local_AUC_score\n",
    "#     print('-'*40)\n",
    "\n",
    "# avg_local_AUC_score = total_AUC/30\n",
    "\n",
    "# print('Avg local AUC score is:', avg_local_AUC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model 15 - RF*5 max vote + GB - weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# import statistics\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import random\n",
    "\n",
    "# y = train_df.outcome.apply(float)\n",
    "# X = train_df[features]\n",
    "\n",
    "# total_AUC = 0\n",
    "\n",
    "# random.seed(30)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "#     rand_state = random.randint(1, 30)\n",
    "#     y = train_df.outcome\n",
    "#     X = train_df[features]\n",
    "#     print('Random_state number', str(i) + ':', rand_state)\n",
    "#     print('-'*40)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "#                                                         shuffle = True)\n",
    "\n",
    "\n",
    "#     model1 = RandomForestClassifier(random_state=5, n_estimators=1400)\n",
    "#     model2 = RandomForestClassifier(random_state=5, n_estimators=1500)\n",
    "#     model3 = RandomForestClassifier(random_state=5, n_estimators=1600)\n",
    "#     model4 = RandomForestClassifier(random_state=5, n_estimators=1700)\n",
    "#     model5 = RandomForestClassifier(random_state=5, n_estimators=1800)\n",
    "#     model6 = GradientBoostingClassifier(learning_rate=0.01,random_state=5)\n",
    "\n",
    "#     model1 = model1.fit(X_train,y_train)\n",
    "#     model2 = model2.fit(X_train,y_train)\n",
    "#     model3 = model3.fit(X_train,y_train)\n",
    "#     model4 = model4.fit(X_train,y_train)\n",
    "#     model5 = model5.fit(X_train,y_train)\n",
    "#     model6 = model6.fit(X_train,y_train)\n",
    "\n",
    "#     pred_proba1 = list((model1.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba2 = list((model2.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba3 = list((model3.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba4 = list((model4.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba5 = list((model5.predict_proba(X_test))[:, 1])\n",
    "#     pred_proba6 = list((model6.predict_proba(X_test))[:, 1])\n",
    "\n",
    "#     test_pred_proba = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         test_pred_proba.append((statistics.mode([pred_proba1[i], pred_proba2[i], pred_proba3[i], \n",
    "#                                                 pred_proba4[i], pred_proba5[i]]) * 0.7) + (pred_proba6[i] * 0.3))\n",
    "    \n",
    "#     local_AUC_score = roc_auc_score(y_test, test_pred_proba)\n",
    "\n",
    "#     print('Local AUC score:', local_AUC_score)\n",
    "#     total_AUC += local_AUC_score\n",
    "#     print('-'*40)\n",
    "\n",
    "# avg_local_AUC_score = total_AUC/30\n",
    "\n",
    "# print('Avg local AUC score is:', avg_local_AUC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------FROM HERE ON EVERYTHING IS FINAL-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model 1: RF+CB+GB (avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4700"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "\n",
    "model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "                                    min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True, \n",
    "                                    criterion = 'entropy')\n",
    "model2 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    "model3 = GradientBoostingClassifier(learning_rate=0.01, random_state=5)\n",
    " \n",
    "model1 = model1.fit(X_train_real, y_train_real)\n",
    "model2 = model2.fit(X_train_real, y_train_real, verbose=False)\n",
    "model3 = model3.fit(X_train_real, y_train_real)\n",
    "\n",
    "pred_proba1 = list((model1.predict_proba(X_test_real))[:, 1])\n",
    "pred_proba2 = list((model2.predict_proba(X_test_real))[:, 1])\n",
    "pred_proba3 = list((model3.predict_proba(X_test_real))[:, 1])\n",
    "\n",
    "final_pred_proba = []\n",
    "for i in range(len(X_test_real)):\n",
    "    final_pred_proba.append(np.mean([pred_proba1[i], pred_proba2[i], pred_proba3[i]]))\n",
    "    \n",
    "len(final_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model 2: RF+CB+GB (weighted avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4700"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "\n",
    "model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "                                    min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True, \n",
    "                                    criterion = 'entropy')\n",
    "model2 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    "model3 = GradientBoostingClassifier(learning_rate=0.01,random_state=5)\n",
    " \n",
    "model1 = model1.fit(X_train_real, y_train_real)\n",
    "model2 = model2.fit(X_train_real, y_train_real, verbose=False)\n",
    "model3 = model3.fit(X_train_real, y_train_real)\n",
    "\n",
    "pred_proba1 = list((model1.predict_proba(X_test_real))[:, 1])\n",
    "pred_proba2 = list((model2.predict_proba(X_test_real))[:, 1])\n",
    "pred_proba3 = list((model3.predict_proba(X_test_real))[:, 1])\n",
    "\n",
    "final_pred_proba = []\n",
    "for i in range(len(X_test_real)):\n",
    "    final_pred_proba.append((pred_proba1[i] * 0.6) + (pred_proba2[i] * 0.2) + (pred_proba3[i] * 0.2))\n",
    "    \n",
    "len(final_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model 3: RF+CB+GB (mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import statistics\n",
    "\n",
    "# model1 = RandomForestClassifier(random_state=5, n_estimators=225)\n",
    "# model2 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    "# model3 = GradientBoostingClassifier(learning_rate=0.01, random_state=5)\n",
    " \n",
    "# model1 = model1.fit(X_train_real, y_train_real)\n",
    "# model2 = model2.fit(X_train_real, y_train_real, verbose=False)\n",
    "# model3 = model3.fit(X_train_real, y_train_real)\n",
    "\n",
    "# pred_proba1 = list((model1.predict_proba(X_test_real))[:, 1])\n",
    "# pred_proba2 = list((model2.predict_proba(X_test_real))[:, 1])\n",
    "# pred_proba3 = list((model3.predict_proba(X_test_real))[:, 1])\n",
    "\n",
    "# final_pred_proba = []\n",
    "# for i in range(len(X_test_real)):\n",
    "#     final_pred_proba.append(statistics.mode([pred_proba1[i], pred_proba2[i], pred_proba3[i]]))\n",
    "    \n",
    "# len(final_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model 4: RF+CB+GB+AB (mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn import datasets\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import statistics\n",
    "\n",
    "# model1 = RandomForestClassifier(random_state=5, n_estimators=225)\n",
    "# model2 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    "# model3 = GradientBoostingClassifier(learning_rate=0.01, random_state=5)\n",
    "# model4 = AdaBoostClassifier(n_estimators=230, learning_rate=0.01)\n",
    "\n",
    "\n",
    "# model1 = model1.fit(X_train_real, y_train_real)\n",
    "# model2 = model2.fit(X_train_real, y_train_real, verbose=False)\n",
    "# model3 = model3.fit(X_train_real, y_train_real)\n",
    "# model4 = model4.fit(X_train_real, y_train_real)\n",
    "\n",
    "# pred_proba1 = list((model1.predict_proba(X_test_real))[:, 1])\n",
    "# pred_proba2 = list((model2.predict_proba(X_test_real))[:, 1])\n",
    "# pred_proba3 = list((model3.predict_proba(X_test_real))[:, 1])\n",
    "# pred_proba4 = list((model4.predict_proba(X_test_real))[:, 1])\n",
    "\n",
    "# final_pred_proba = []\n",
    "# for i in range(len(X_test_real)):\n",
    "#     final_pred_proba.append(np.mean([pred_proba1[i], pred_proba2[i], pred_proba3[i]]))\n",
    "    \n",
    "# len(final_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model 5: RF+CB (avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import statistics\n",
    "\n",
    "# model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "#                                     min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True, \n",
    "#                                     criterion = 'entropy')\n",
    "# model2 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    " \n",
    "# model1 = model1.fit(X_train_real,y_train_real)\n",
    "# model2 = model2.fit(X_train_real,y_train_real,verbose=False)\n",
    "\n",
    "# pred_proba1 = list((model1.predict_proba(X_test_real))[:, 1])\n",
    "# pred_proba2 = list((model2.predict_proba(X_test_real))[:, 1])\n",
    "\n",
    "# final_pred_proba = []\n",
    "# for i in range(len(X_test_real)):\n",
    "#     final_pred_proba.append(np.mean([pred_proba1[i], pred_proba2[i]]))\n",
    "    \n",
    "# len(final_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model 6: RF+CB (weighted avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import statistics\n",
    "\n",
    "# model1 = RandomForestClassifier(random_state=5, n_estimators=225)\n",
    "# model2 = CatBoostClassifier(random_seed=5) #iterations=1000,depth=7,l2_leaf_reg=0\n",
    " \n",
    "# model1 = model1.fit(X_train_real,y_train_real)\n",
    "# model2 = model2.fit(X_train_real,y_train_real,verbose=False)\n",
    "\n",
    "# pred_proba1 = list((model1.predict_proba(X_test_real))[:, 1])\n",
    "# pred_proba2 = list((model2.predict_proba(X_test_real))[:, 1])\n",
    "\n",
    "# final_pred_proba = []\n",
    "# for i in range(len(X_test_real)):\n",
    "#     final_pred_proba.append((pred_proba1[i] * 0.7) + (pred_proba2[i] * 0.3))\n",
    "    \n",
    "# len(final_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model 7: RF*5 (avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import metrics\n",
    "# import statistics\n",
    "\n",
    "# model1 = RandomForestClassifier(random_state=5, n_estimators=200)\n",
    "# model2 = RandomForestClassifier(random_state=5, n_estimators=205)\n",
    "# model3 = RandomForestClassifier(random_state=5, n_estimators=215)\n",
    "# model4 = RandomForestClassifier(random_state=5, n_estimators=220)\n",
    "# model5 = RandomForestClassifier(random_state=5, n_estimators=225)\n",
    " \n",
    "# model1 = model1.fit(X_train_real,y_train_real)\n",
    "# model2 = model2.fit(X_train_real,y_train_real)\n",
    "# model3 = model3.fit(X_train_real,y_train_real)\n",
    "# model4 = model4.fit(X_train_real,y_train_real)\n",
    "# model5 = model5.fit(X_train_real,y_train_real)\n",
    "\n",
    "# pred_proba1 = list((model1.predict_proba(X_test_real))[:, 1])\n",
    "# pred_proba2 = list((model2.predict_proba(X_test_real))[:, 1])\n",
    "# pred_proba3 = list((model3.predict_proba(X_test_real))[:, 1])\n",
    "# pred_proba4 = list((model4.predict_proba(X_test_real))[:, 1])\n",
    "# pred_proba5 = list((model5.predict_proba(X_test_real))[:, 1])\n",
    "\n",
    "# final_pred_proba = []\n",
    "# for i in range(len(X_test_real)):\n",
    "#     final_pred_proba.append(np.mean([pred_proba1[i], pred_proba2[i], pred_proba3[i], pred_proba4[i], pred_proba5[i]]))\n",
    "    \n",
    "# len(final_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model 8: RF + GB - weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4700"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "\n",
    "model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "                                    min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True, \n",
    "                                    criterion = 'entropy')\n",
    "model2 = GradientBoostingClassifier(learning_rate=0.01,random_state=5)\n",
    "\n",
    "model1 = model1.fit(X_train_real,y_train_real)\n",
    "model2 = model2.fit(X_train_real, y_train_real)\n",
    "\n",
    "pred_proba1 = list((model1.predict_proba(X_test_real))[:, 1])\n",
    "pred_proba2 = list((model2.predict_proba(X_test_real))[:, 1])\n",
    "\n",
    "final_pred_proba = []\n",
    "for i in range(len(X_test_real)):\n",
    "    final_pred_proba.append((pred_proba1[i] * 0.7) + (pred_proba2[i] * 0.3))\n",
    "    \n",
    "len(final_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORMING THE CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidder_id_list = list(test_df.bidder_id) #4.7 bidders\n",
    "predictions_list = final_pred_proba #predict proba list\n",
    "\n",
    "pred_list = [['Id','Predicted']]\n",
    "for i in range(len(predictions_list)):\n",
    "    pred_list.append([bidder_id_list[i],predictions_list[i]])\n",
    "df = pd.DataFrame(pred_list[1:], columns = pred_list[0])\n",
    "\n",
    "df.to_csv('RF_GB_avg_final3.csv', index=False) # change file name everytime you have a new set of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------EXTRA STUFF -----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for SKLearn Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4b.iii) Parameters you can tinker in SKLearn Random Forest</b>\n",
    "\n",
    "There are various parameters which you can pass to the <code>RandomForestClassifier()</code> function. We have listed them below for you, and we <b>highly recommend that you take some time to read through them, and tinker with them so that you better understand their behavior</b>:\n",
    "\n",
    "- <code>n_estimators</code>:\n",
    "    - It defines the number of decision trees to be created in a random forest (the default value is 100).\n",
    "    - Generally, a higher number makes the predictions better and more stable, but a very large number can be computationally expensive.<br><br>\n",
    "- <code>criterion</code>:\n",
    "    - It defines the function that is to be used for splitting.\n",
    "    - The function measures the quality of a split for each feature and chooses the best split.<br><br>\n",
    "- <code>max_features</code>:\n",
    "    - It defines the maximum number of features allowed for the split in each decision tree.\n",
    "    - Increasing max features usually improve performance but a very high number can decrease the diversity of each tree.<br><br>\n",
    "- <code>max_depth</code>:\n",
    "    - Random forest has multiple decision trees. This parameter defines the maximum depth of the trees.<br><br>\n",
    "- <code>min_samples_split</code>:\n",
    "    - Used to define the minimum number of samples required in a leaf node before a split is attempted.\n",
    "    - If the number of samples is less than the required number, the node is not split.<br><br>\n",
    "- <code>min_samples_leaf</code>:\n",
    "    - This defines the minimum number of samples required to be at a leaf node.\n",
    "    - Smaller leaf size makes the model more prone to capturing noise in train data.<br><br>\n",
    "- <code>max_leaf_nodes</code>:\n",
    "    - This parameter specifies the maximum number of leaf nodes for each tree.\n",
    "    - The tree stops splitting when the number of leaf nodes becomes equal to the max leaf node.<br><br>\n",
    "- <code>n_jobs</code>:\n",
    "    - This indicates the number of jobs to run in parallel.\n",
    "    - Set value to -1 if you want it to run on all cores in the system.<br><br>\n",
    "- <code>random_state</code>:\n",
    "    - This parameter is used to define the random selection.\n",
    "    - It is used for comparison between various models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Validation using train_df and calculating AUC score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # Split data into predictors X and output Y\n",
    "# y = train_df.outcome\n",
    "# X = train_df[features]\n",
    "\n",
    "# # Split the data into ten sets\n",
    "# kf = KFold(n_splits=10)\n",
    "\n",
    "# # Create logistic regression object\n",
    "# log_reg = LogisticRegression(max_iter=300)\n",
    "\n",
    "# # List of accuracy for each fold\n",
    "# k_fold_accuracy = []\n",
    "\n",
    "# # Iterate through each fold and calculate the RMSE for each fold\n",
    "# for train_index, test_index in kf.split(X):\n",
    "    \n",
    "#     # Extract the training and test data\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Random Forest Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1000, stop = 10000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.outcome.apply(float)\n",
    "X = train_df[features]\n",
    "\n",
    "# random.seed(30)\n",
    "\n",
    "# for i in range (1, 31):\n",
    "# rand_state = random.randint(1, 30)\n",
    "y = train_df.outcome\n",
    "X = train_df[features]\n",
    "# print('Random_state number', str(i) + ':', rand_state)\n",
    "# print('-'*40)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 5, \n",
    "                                                    shuffle = True)\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3 , \n",
    "                               verbose=2, random_state=5, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    errors = abs(predictions - y_test)\n",
    "    mape = 100 * np.mean(errors / y_test)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {'n_estimators': [700, 800, 900, 1000, 1100, 2000],\n",
    "             'min_samples_split': [3, 5, 7],\n",
    "             'min_samples_leaf': [1, 2, 3],\n",
    "             'max_features': [35, 36],\n",
    "             'max_depth': [110, 120, 130, 140],\n",
    "             'bootstrap': [True]}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing CatBoost Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = RandomForestClassifier(random_state=5, n_estimators=2200, min_samples_split =  5,\n",
    "#                                     min_samples_leaf = 2, max_features = 'auto', max_depth = 100, bootstrap = True, \n",
    "#                                     criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "y = train_df.outcome\n",
    "X = train_df[features]\n",
    "\n",
    "rand_state = random.randint(1, 30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "                                                    shuffle = True)\n",
    "\n",
    "CBC = CatBoostClassifier()\n",
    "\n",
    "params = {'depth':[3,1,2,6,4,5,7,8,9,10],\n",
    "      'iterations':[1800, 1900, 2000, 2100, 2200],\n",
    "      'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3], \n",
    "      'l2_leaf_reg':[3,1,5,10,100],\n",
    "      'border_count':[32,5,10,20,50,100,200],\n",
    "      'ctr_border_count':[50,5,10,20,100,200],\n",
    "      'thread_count':4}\n",
    "\n",
    "Grid_CBC = GridSearchCV(estimator=CBC, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "Grid_CBC.fit(X_train, y_train)\n",
    "\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",Grid_CBC.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",Grid_CBC.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",Grid_CBC.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing GradientBoost Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = train_df.outcome\n",
    "X = train_df[features]\n",
    "\n",
    "rand_state = random.randint(1, 30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = rand_state, \n",
    "                                                    shuffle = True)\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# model = GradientBoostingClassifier(learning_rate=0.01,random_state=5)\n",
    "# model.fit(x_train, y_train)\n",
    "# y_pred = model.predict_proba(x_test)\n",
    "\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "# roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "\n",
    "learning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
    "train_results = []\n",
    "test_results = []\n",
    "for eta in learning_rates:\n",
    "   model = GradientBoostingClassifier(learning_rate=eta)\n",
    "   model.fit(X_train, y_train)\n",
    "   train_pred = model.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = model.predict_proba(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "    \n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(learning_rates, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(learning_rates, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('learning rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [1800, 1900, 2000, 2100, 2200]\n",
    "train_results = []\n",
    "test_results = []\n",
    "for estimator in n_estimators:\n",
    "   model = GradientBoostingClassifier(n_estimators=estimator)\n",
    "   model.fit(x_train, y_train)\n",
    "   train_pred = model.predict(x_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = model.predict(x_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.linspace(1, 100, 10, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "   model = GradientBoostingClassifier(max_depth=max_depth)\n",
    "   model.fit(x_train, y_train)\n",
    "   train_pred = model.predict(x_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = model.predict(x_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_depths, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_splits = np.linspace(1.0, 7.0, 10, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_split in min_samples_splits:\n",
    "   model = GradientBoostingClassifier(min_samples_split=min_samples_split)\n",
    "   model.fit(x_train, y_train)\n",
    "   train_pred = model.predict(x_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = model.predict(x_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(min_samples_splits, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(min_samples_splits, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('min samples split')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leafs = np.linspace(0.5, 3, 5, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "   model = GradientBoostingClassifier(min_samples_leaf=min_samples_leaf)\n",
    "   model.fit(x_train, y_train)\n",
    "   train_pred = model.predict(x_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = model.predict(x_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(min_samples_leafs, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(min_samples_leafs, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('min samples leafs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = list(range(1,train_df.shape[1]))\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_feature in max_features:\n",
    "   model = GradientBoostingClassifier(max_features=max_feature)\n",
    "   model.fit(x_train, y_train)\n",
    "   train_pred = model.predict(x_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = model.predict(x_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_features, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(max_features, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('max features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
